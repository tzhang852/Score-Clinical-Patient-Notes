{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Exact Text Matcher\n",
    "The contest provided a substantial amount of data to classify, and a comparatively tiny amount of training data. Our intended approach to classify the raw data relies on some form of neural network implementation. Generally, neural networks improve performance when given more training data to work with. While we don't have a medical expert handy to manually label more data to get more training data intelligently, we do have the next best thing. We can make Python code that gets a large amount of training data that we can be sure is accurate very, very unintelligently.\n",
    "\n",
    "The following code identifies every pattern that is known to indicate a diagnosable feature, finds all instances of those patterns in the raw data, and labels them to expand the available training data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "outputs": [],
   "source": [
    "import pandas as pd # for data handling\n",
    "import re # for string manipulation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importing the necessary dataframes:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "outputs": [],
   "source": [
    "path = 'nbme-score-clinical-patient-notes/'\n",
    "features = pd.read_csv(path + '/features.csv')\n",
    "pn = pd.read_csv(path + '/patient_notes.csv')\n",
    "train = pd.read_csv(path + '/train.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Building a dictionary of text identifiers for every feature:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "outputs": [],
   "source": [
    "feature_identifiers = {} # Keys are feature numbers, values are sets full of every text annotation labeled as that feature number\n",
    "# loops through every feature to collect information\n",
    "for feature_id in features['feature_num'].unique():\n",
    "    identifying_text = set() # set to hold unique identifiers for current diagnosable feature\n",
    "    feature_annotations = train[train['feature_num'] == feature_id]['annotation'].unique().tolist() # gets all unique lists of identifiers\n",
    "    # loops through all lists to retrieve the individual unique text identifiers\n",
    "    for note_annotation in feature_annotations:\n",
    "        matchable_texts = eval(note_annotation)\n",
    "        for text in matchable_texts:\n",
    "            identifying_text.add(text) # adds the string to the set\n",
    "    feature_identifiers[feature_id] = identifying_text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Removing patient notes that have already been labeled to avoid redundant processing:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "outputs": [],
   "source": [
    "already_annotated = train['pn_num'].unique().tolist()\n",
    "trimmed_notes = pn[~pn['pn_num'].isin(already_annotated)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initializing a dataframe for building the extension of training data:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "outputs": [],
   "source": [
    "train_extension = pd.DataFrame(columns=['id', 'case_num', 'pn_num', 'feature_num', 'annotation', 'unformatted_location'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loop for patient note entry\n",
    "for idx, row in trimmed_notes.iterrows():\n",
    "    text = row['pn_history'] # The full text of the current patient note\n",
    "    # Loop for each feature to compare it to the note\n",
    "    for feature_num in feature_identifiers.keys():\n",
    "        # Loop for identifying text\n",
    "        feature_texts = list(sorted(feature_identifiers[feature_num], key= len, reverse=True)) # orders texts by descending length\n",
    "        feature_spans = [] # holds spans to be used in expanded data set\n",
    "        feature_annotations = [] # holds annotations matched in the text\n",
    "\n",
    "\n",
    "        for matchable_text in feature_texts:\n",
    "            # Avoids short strings like the \"f\" annotation being found in almost every patient note\n",
    "            pattern = re.compile(fr\"(?<!\\w){matchable_text}(?!\\w)\")\n",
    "            new_spans = [(m.start(), m.end()) for m in re.finditer(pattern, text)]\n",
    "\n",
    "            # Processes found spans\n",
    "            if len(new_spans) > 0:\n",
    "                no_conflict = True\n",
    "                # Checks if the found spans overlap with any already-known spans\n",
    "                for new_span in new_spans:\n",
    "                    for old_span in feature_spans:\n",
    "                        if new_span[0] > old_span[0] and new_span[1] < old_span[1]:\n",
    "                                no_conflict = False\n",
    "                    # If the new span doesn't overlap already known spans, it's added to the list of known spans\n",
    "                    if no_conflict:\n",
    "                        feature_spans.append(new_span)\n",
    "                        feature_annotations.append(matchable_text)\n",
    "\n",
    "        # Creates a row entry in the train_extension dataframe representing the found data\n",
    "        if len(feature_spans) > 0:\n",
    "            train_extension.loc[train_extension.shape[0]] = {'case_num': row['case_num'], 'pn_num': row['pn_num'], 'feature_num': feature_num, \\\n",
    "                                                             'annotation': feature_annotations, 'unformatted_location': feature_spans}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The steps taken to find and compare all of these new spans resulted in lists of integers representing spans, e.g. [(1, 5), (10, 13)]\n",
    "\n",
    "The data in the train dataframe is, somewhat inexplicably, formatted as string representations of lists of strings without commas, e.g. \"['1 5', '10 13']\"\n",
    "\n",
    "Perhaps there's some reason for this that will become clear later when we're dealing with the transformer neural network. Perhaps not. In case it matters, the following code formats the new column accordingly."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "outputs": [],
   "source": [
    "def format_location(entry):\n",
    "    span_list = entry['location']\n",
    "    stringy_list = \"[\"\n",
    "\n",
    "    for span in span_list:\n",
    "        string_rep = \"'{start:n} {end:n}', \".format(start = span[0], end = span[1])\n",
    "        stringy_list = stringy_list + string_rep\n",
    "    stringy_list = stringy_list[:-2] + ']'\n",
    "    return stringy_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "outputs": [],
   "source": [
    "train_extension['unformatted_location'] = train_extension.apply(format_location, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "outputs": [
    {
     "data": {
      "text/plain": "   id  case_num  pn_num  feature_num        annotation unformatted_location  \\\n0 NaN         0       0            0   [father had MI]         [(553, 566)]   \n1 NaN         0       0            2      [chest pain]         [(432, 442)]   \n2 NaN         0       0            3    [intermittent]         [(216, 228)]   \n3 NaN         0       0            6          [aderol]         [(520, 526)]   \n4 NaN         0       0            9  [heart pounding]           [(71, 85)]   \n\n      location  \n0  ['553 566']  \n1  ['432 442']  \n2  ['216 228']  \n3  ['520 526']  \n4    ['71 85']  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>case_num</th>\n      <th>pn_num</th>\n      <th>feature_num</th>\n      <th>annotation</th>\n      <th>unformatted_location</th>\n      <th>location</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[father had MI]</td>\n      <td>[(553, 566)]</td>\n      <td>['553 566']</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>[chest pain]</td>\n      <td>[(432, 442)]</td>\n      <td>['432 442']</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>[intermittent]</td>\n      <td>[(216, 228)]</td>\n      <td>['216 228']</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>[aderol]</td>\n      <td>[(520, 526)]</td>\n      <td>['520 526']</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>[heart pounding]</td>\n      <td>[(71, 85)]</td>\n      <td>['71 85']</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_extension.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "outputs": [],
   "source": [
    "train_extension.to_csv(path + '/train_extension.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}